<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>Markmap</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
</style>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/markmap-toolbar@0.18.8/dist/style.css">
</head>
<body>
<svg id="mindmap"></svg>
<script src="https://cdn.jsdelivr.net/npm/d3@7.9.0/dist/d3.min.js"></script><script src="https://cdn.jsdelivr.net/npm/markmap-view@0.18.8/dist/browser/index.js"></script><script src="https://cdn.jsdelivr.net/npm/markmap-toolbar@0.18.8/dist/index.js"></script><script>(()=>{setTimeout(()=>{const{markmap:x,mm:K}=window,P=new x.Toolbar;P.attach(K);const F=P.render();F.setAttribute("style","position:absolute;bottom:20px;right:20px"),document.body.append(F)})})()</script><script>((b,L,T,D)=>{const H=b();window.mm=H.Markmap.create("svg#mindmap",(L||H.deriveOptions)(D),T)})(()=>window.markmap,null,{"content":"📊 <strong>Detecting Visual Text 心智圖筆記</strong>","children":[{"content":"📚 1. Introduction","children":[{"content":"<strong>研究動機</strong> 🎯","children":[{"content":"人類在描述場景時，常結合視覺與非視覺資訊","children":[],"payload":{"tag":"li","lines":"4,5"}},{"content":"目標：自動區分描述影像的視覺文本（Visual Text）與非視覺文本","children":[],"payload":{"tag":"li","lines":"5,6"}}],"payload":{"tag":"li","lines":"3,6"}},{"content":"<strong>應用場景</strong> 🌐","children":[{"content":"影像檢索系統","children":[],"payload":{"tag":"li","lines":"7,8"}},{"content":"自動化影像標註（如協助視障人士）","children":[],"payload":{"tag":"li","lines":"8,9"}},{"content":"訓練物件偵測模型","children":[],"payload":{"tag":"li","lines":"9,11"}}],"payload":{"tag":"li","lines":"6,11"}}],"payload":{"tag":"h2","lines":"2,3"}},{"content":"🔍 2. Data Analysis","children":[{"content":"📊 2.1 Data Sets","children":[{"content":"<strong>視覺資料集</strong> 🖼️","children":[{"content":"SBU Captioned Photo Dataset（100萬張帶有標註的影像）","children":[],"payload":{"tag":"li","lines":"16,17"}}],"payload":{"tag":"li","lines":"15,17"}},{"content":"<strong>非視覺資料集</strong> 📄","children":[{"content":"ukWaC","children":[],"payload":{"tag":"li","lines":"18,19"}},{"content":"New York Times Newswire（Gigaword Corpus）","children":[],"payload":{"tag":"li","lines":"19,21"}}],"payload":{"tag":"li","lines":"17,21"}}],"payload":{"tag":"h3","lines":"14,15"}},{"content":"🧩 2.2 Formalizing Visual Text","children":[{"content":"<strong>視覺文本定義</strong> 🔑","children":[{"content":"如果能將影像中的某部分裁切出來，放入任何影像中，第三者仍可用相同方式描述，則該文本為視覺文本","children":[],"payload":{"tag":"li","lines":"23,24"}}],"payload":{"tag":"li","lines":"22,24"}},{"content":"<strong>挑戰</strong> ⚠️","children":[{"content":"<strong>模糊界線</strong>：如 \"Hanbury St.\" 是推論還是直接可見？","children":[],"payload":{"tag":"li","lines":"25,26"}},{"content":"<strong>主觀推測</strong>：描述可能包含攝影者背景知識","children":[],"payload":{"tag":"li","lines":"26,28"}}],"payload":{"tag":"li","lines":"24,28"}}],"payload":{"tag":"h3","lines":"21,22"}},{"content":"📏 2.3 Most Pronounced Differences","children":[{"content":"<strong>語法特徵差異</strong> ⚡","children":[{"content":"Flickr 描述中的實體物件更多","children":[],"payload":{"tag":"li","lines":"30,31"}},{"content":"非視覺文本中抽象概念佔比更高","children":[],"payload":{"tag":"li","lines":"31,32"}}],"payload":{"tag":"li","lines":"29,32"}},{"content":"<strong>修飾語分析</strong> ✍️","children":[{"content":"Flickr 中 50% 的名詞修飾語與顏色相關","children":[],"payload":{"tag":"li","lines":"33,34"}},{"content":"非視覺文本中，尺寸與抽象概念的修飾語佔比較高","children":[],"payload":{"tag":"li","lines":"34,36"}}],"payload":{"tag":"li","lines":"32,36"}}],"payload":{"tag":"h3","lines":"28,29"}},{"content":"🗂️ 2.4 Annotating Visual Text","children":[{"content":"<strong>標註方式</strong> 🏷️","children":[{"content":"使用 Amazon Mechanical Turk 進行眾包標註","children":[],"payload":{"tag":"li","lines":"38,39"}},{"content":"標註類別：視覺（Visual）、非視覺（Non-Visual）、錯誤（Error）","children":[],"payload":{"tag":"li","lines":"39,40"}}],"payload":{"tag":"li","lines":"37,40"}},{"content":"<strong>數據集</strong>","children":[{"content":"SMALL dataset：803張圖片，2339個標註","children":[],"payload":{"tag":"li","lines":"41,42"}},{"content":"LARGE dataset：48,000張圖片","children":[],"payload":{"tag":"li","lines":"42,44"}}],"payload":{"tag":"li","lines":"40,44"}}],"payload":{"tag":"h3","lines":"36,37"}}],"payload":{"tag":"h2","lines":"13,14"}},{"content":"🤖 3. Visual Features from Raw Text","children":[{"content":"🚀 3.1 Bootstrapping for Visual Text","children":[{"content":"<strong>技術方法</strong> 🔄","children":[{"content":"使用種子詞進行詞彙擴展","children":[],"payload":{"tag":"li","lines":"49,50"}},{"content":"基於 PMI（Pointwise Mutual Information）計算詞彙間相似度","children":[],"payload":{"tag":"li","lines":"50,51"}}],"payload":{"tag":"li","lines":"48,51"}},{"content":"<strong>視覺與非視覺詞彙例子</strong> 🗣️","children":[{"content":"視覺名詞：car, house, tree","children":[],"payload":{"tag":"li","lines":"52,53"}},{"content":"非視覺名詞：idea, honesty, trust","children":[],"payload":{"tag":"li","lines":"53,55"}}],"payload":{"tag":"li","lines":"51,55"}}],"payload":{"tag":"h3","lines":"47,48"}},{"content":"🌐 3.2 Label Propagation","children":[{"content":"<strong>標籤傳播法</strong> 🔗","children":[{"content":"構建二分圖，節點分為謂語（VP）與名詞（VA）","children":[],"payload":{"tag":"li","lines":"57,58"}},{"content":"使用語義距離進行詞彙分類","children":[],"payload":{"tag":"li","lines":"58,60"}}],"payload":{"tag":"li","lines":"56,60"}}],"payload":{"tag":"h3","lines":"55,56"}},{"content":"🎨 3.3 Visual Adjectives Bootstrapping","children":[{"content":"<strong>屬性分類</strong> 🏷️","children":[{"content":"顏色（Color）：purple, green, silver","children":[],"payload":{"tag":"li","lines":"62,63"}},{"content":"材質（Material）：cotton, wooden, metallic","children":[],"payload":{"tag":"li","lines":"63,64"}},{"content":"形狀（Shape）：circular, rectangular, triangular","children":[],"payload":{"tag":"li","lines":"64,66"}}],"payload":{"tag":"li","lines":"61,66"}}],"payload":{"tag":"h3","lines":"60,61"}}],"payload":{"tag":"h2","lines":"46,47"}},{"content":"📈 4. Recognizing Visual Text","children":[{"content":"⚙️ 4.1 Classifier Design","children":[{"content":"<strong>模型選擇</strong> 🤖","children":[{"content":"使用 Logistic Regression（二元邏輯回歸）","children":[],"payload":{"tag":"li","lines":"71,72"}}],"payload":{"tag":"li","lines":"70,72"}},{"content":"<strong>特徵類型</strong> 🔍","children":[{"content":"詞彙特徵（WORDS）、雙詞組（BIGRAMS）","children":[],"payload":{"tag":"li","lines":"73,74"}},{"content":"詞形特徵（SPELL）、WordNet 層級、Bootstrap 特徵","children":[],"payload":{"tag":"li","lines":"74,76"}}],"payload":{"tag":"li","lines":"72,76"}}],"payload":{"tag":"h3","lines":"69,70"}},{"content":"🏆 4.2 Performance Evaluation","children":[{"content":"<strong>評估指標</strong> 📊","children":[{"content":"使用 ROC 曲線下的面積（AUC）進行性能評估","children":[],"payload":{"tag":"li","lines":"78,79"}}],"payload":{"tag":"li","lines":"77,79"}},{"content":"<strong>重要發現</strong> 🔎","children":[{"content":"SMALL dataset：AUC ≈ 71.3%","children":[],"payload":{"tag":"li","lines":"80,81"}},{"content":"LARGE dataset：AUC ≈ 76.1%","children":[],"payload":{"tag":"li","lines":"81,82"}},{"content":"結合圖像特徵後，AUC 提升至 76.8%","children":[],"payload":{"tag":"li","lines":"82,84"}}],"payload":{"tag":"li","lines":"79,84"}}],"payload":{"tag":"h3","lines":"76,77"}},{"content":"🚩 4.3 Feature Ablation","children":[{"content":"<strong>特徵重要性分析</strong> 🔍","children":[{"content":"最有價值特徵：Bootstrap 特徵、詞彙特徵、拼寫特徵","children":[],"payload":{"tag":"li","lines":"86,87"}},{"content":"圖像特徵在數據較少時效果更明顯","children":[],"payload":{"tag":"li","lines":"87,89"}}],"payload":{"tag":"li","lines":"85,89"}}],"payload":{"tag":"h3","lines":"84,85"}}],"payload":{"tag":"h2","lines":"68,69"}},{"content":"🧠 5. Discussion &amp; Conclusion","children":[{"content":"<strong>研究貢獻</strong> 🎓","children":[{"content":"首次系統化定義與檢測視覺文本的方法","children":[],"payload":{"tag":"li","lines":"93,94"}},{"content":"結合 NLP 與 Computer Vision 提升文本理解能力","children":[],"payload":{"tag":"li","lines":"94,95"}}],"payload":{"tag":"li","lines":"92,95"}},{"content":"<strong>未來工作方向</strong> 🚀","children":[{"content":"擴展到更多語言與多模態數據","children":[],"payload":{"tag":"li","lines":"96,97"}},{"content":"優化模型在噪音數據下的表現","children":[],"payload":{"tag":"li","lines":"97,99"}}],"payload":{"tag":"li","lines":"95,99"}}],"payload":{"tag":"h2","lines":"91,92"}},{"content":"🤝 Acknowledgments","children":[{"content":"感謝 NSF、Stony Brook University 等機構支持","children":[],"payload":{"tag":"li","lines":"102,103"}}],"payload":{"tag":"h2","lines":"101,102"}}],"payload":{"tag":"h1","lines":"0,1"}},null)</script>
</body>
</html>
